{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Uber Driver Data Analysis\n",
    "\n",
    "This notebook analyzes driver performance, earnings, and behavior patterns from the Uber hackathon dataset."
   ],
   "id": "7ce16003fd04d33a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Import Libraries and Load Data",
   "id": "6972cc875b1db9ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install -U pip\n",
    "!pip install pandas matplotlib seaborn openpyxl"
   ],
   "id": "6316f941ac85d366"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100"
   ],
   "id": "4a6610d09e49bcf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# Load all sheets from the Excel file\n",
    "# ---------------------------\n",
    "file_path = \"uber_hackathon_v2_mock_data.xlsx\"\n",
    "sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# Assign sheets to variables\n",
    "earners = sheets['earners']\n",
    "rides_trips = sheets['rides_trips']\n",
    "earnings_daily = sheets['earnings_daily']\n",
    "incentives_weekly = sheets['incentives_weekly']\n",
    "cancellation_rates = sheets['cancellation_rates']\n",
    "surge_by_hour = sheets.get('surge_by_hour')        # optional\n",
    "weather_daily = sheets.get('weather_daily')        # optional\n",
    "heatmap_sheet = sheets.get('heatmap')              # optional\n",
    "jobs_like = sheets.get('jobs_like')                # optional\n",
    "\n",
    "# Convert datetime columns\n",
    "rides_trips['start_time'] = pd.to_datetime(rides_trips['start_time'])\n",
    "rides_trips['end_time'] = pd.to_datetime(rides_trips['end_time'])\n",
    "earnings_daily['date'] = pd.to_datetime(earnings_daily['date'])\n",
    "\n",
    "print(f\"Loaded {len(sheets)} sheets from {file_path}\")\n",
    "print(f\"\\nEarners: {len(earners)} records\")\n",
    "print(f\"Rides/Trips: {len(rides_trips)} records\")\n",
    "print(f\"Daily Earnings: {len(earnings_daily)} records\")\n",
    "print(f\"Weekly Incentives: {len(incentives_weekly)} records\")"
   ],
   "id": "fb3c0709d095a4f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Earnings vs Working Time",
   "id": "6b88df6c14ee452f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# 1. Earnings vs Working Time\n",
    "# ---------------------------\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x='rides_duration_mins', y='total_net_earnings', data=earnings_daily, alpha=0.5)\n",
    "plt.title('Earnings vs. Working Time')\n",
    "plt.xlabel('Rides Duration (mins)')\n",
    "plt.ylabel('Total Net Earnings (â‚¬)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "bb5435dc8b2436c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Trips per Day Distribution",
   "id": "c963c9b29b26321d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# 2. Trips per Day Distribution\n",
    "# ---------------------------\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(earnings_daily['trips_count'], bins=15, kde=False)\n",
    "plt.title('Trips per Day Distribution')\n",
    "plt.xlabel('Trips per Day')\n",
    "plt.ylabel('Number of Drivers')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "a248d444ac846ba0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Hourly Earnings Curve",
   "id": "50e4f7051f7b13e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# 3. Hourly Earnings Curve\n",
    "# ---------------------------\n",
    "rides_trips['hour'] = rides_trips['start_time'].dt.hour\n",
    "hourly_earnings = rides_trips.groupby('hour')['net_earnings'].mean().reset_index()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.lineplot(x='hour', y='net_earnings', data=hourly_earnings, marker='o')\n",
    "plt.title('Hourly Earnings Curve')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Average Net Earnings (â‚¬)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "59cc832b5d1cbc5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Idle Time Analysis",
   "id": "44e4f9fbf9bac5da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# 4. Idle Time Analysis\n",
    "# ---------------------------\n",
    "rides_trips_sorted = rides_trips.sort_values(['driver_id','start_time'])\n",
    "rides_trips_sorted['next_start'] = rides_trips_sorted.groupby('driver_id')['start_time'].shift(-1)\n",
    "rides_trips_sorted['idle_time_mins'] = (rides_trips_sorted['next_start'] - rides_trips_sorted['end_time']).dt.total_seconds()/60\n",
    "\n",
    "# Filter out negative and extreme values\n",
    "rides_trips_filtered = rides_trips_sorted[(rides_trips_sorted['idle_time_mins'] > 0) & \n",
    "                                           (rides_trips_sorted['idle_time_mins'] < 300)]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x='idle_time_mins', y='net_earnings', data=rides_trips_filtered, alpha=0.5)\n",
    "plt.title('Idle Time vs Earnings')\n",
    "plt.xlabel('Idle Time (mins)')\n",
    "plt.ylabel('Net Earnings (â‚¬)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6774baa7b29da131"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Weekly Incentives Effect",
   "id": "6fbe3ac25adca46c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# 5. Weekly Incentives Effect\n",
    "# ---------------------------\n",
    "weekly_earnings = earnings_daily.groupby('earner_id').agg({'total_net_earnings':'sum'}).reset_index()\n",
    "weekly_data = weekly_earnings.merge(incentives_weekly, on='earner_id', how='left')\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x='bonus_eur', y='total_net_earnings', data=weekly_data, alpha=0.5)\n",
    "plt.title('Weekly Incentives vs Total Earnings')\n",
    "plt.xlabel('Bonus (â‚¬)')\n",
    "plt.ylabel('Total Net Earnings (â‚¬)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b5c3578b8aabf01b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Driver Rating vs Workload",
   "id": "e5e1b9ed191ae905"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# 6. Driver Rating vs Workload\n",
    "# ---------------------------\n",
    "driver_workload = rides_trips.groupby('driver_id')['duration_mins'].mean().reset_index()\n",
    "rating_workload = driver_workload.merge(earners[['earner_id','rating']], \n",
    "                                         left_on='driver_id', \n",
    "                                         right_on='earner_id', \n",
    "                                         how='left')\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x='duration_mins', y='rating', data=rating_workload, alpha=0.5)\n",
    "plt.title('Driver Rating vs Average Workload')\n",
    "plt.xlabel('Average Trip Duration (mins)')\n",
    "plt.ylabel('Driver Rating')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "191cf6ac1eb3bf32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. Cancellation Rate vs Surge",
   "id": "7852a986a7426361"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# 7. Cancellation Rate vs Surge\n",
    "# ---------------------------\n",
    "if surge_by_hour is not None:\n",
    "    # Add hour column to cancellation_rates if needed\n",
    "    # For this analysis, we'll aggregate by city\n",
    "    cancellation_city = cancellation_rates.groupby('city_id').agg({\n",
    "        'cancellation_rate_pct': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    surge_city = surge_by_hour.groupby('city_id').agg({\n",
    "        'surge_multiplier': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    cancellation_surge = cancellation_city.merge(surge_city, on='city_id', how='left')\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(x='surge_multiplier', y='cancellation_rate_pct', \n",
    "                    data=cancellation_surge, s=100)\n",
    "    plt.title('Cancellation Rate vs Surge Multiplier (by City)')\n",
    "    plt.xlabel('Average Surge Multiplier')\n",
    "    plt.ylabel('Average Cancellation Rate (%)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Surge data not available\")"
   ],
   "id": "973fa14c19304f52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. Fatigue Heatmap - Trips by Hour and Day",
   "id": "d9a9f5f3509381d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# 8. Fatigue Heatmap\n",
    "# ---------------------------\n",
    "rides_trips['day_of_week'] = rides_trips['start_time'].dt.day_name()\n",
    "heatmap_data = rides_trips.pivot_table(index='hour', \n",
    "                                        columns='day_of_week', \n",
    "                                        values='ride_id', \n",
    "                                        aggfunc='count')\n",
    "\n",
    "# Reorder columns to show days in proper order\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "heatmap_data = heatmap_data[[col for col in day_order if col in heatmap_data.columns]]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(heatmap_data, cmap='YlOrRd', annot=True, fmt='g', cbar_kws={'label': 'Number of Trips'})\n",
    "plt.title('Fatigue Heatmap: Trips per Hour by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Hour of Day')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "8ba253762fb86587"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10. Driver Performance Table - Trips, Duration & Profits per Day",
   "id": "392618d2af1576c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# Driver Performance Table: Trips, Duration & Profits per Day\n",
    "# ---------------------------\n",
    "\n",
    "# Create a comprehensive table showing driver performance metrics per day\n",
    "driver_daily_summary = earnings_daily.copy()\n",
    "\n",
    "# Add driver information (rating, etc.)\n",
    "driver_daily_summary = driver_daily_summary.merge(\n",
    "    earners[['earner_id', 'rating']],\n",
    "    on='earner_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add day of week for better readability\n",
    "driver_daily_summary['day_of_week'] = driver_daily_summary['date'].dt.day_name()\n",
    "driver_daily_summary['date_formatted'] = driver_daily_summary['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Create the summary table with key metrics\n",
    "performance_table = driver_daily_summary[[\n",
    "    'earner_id', 'date_formatted', 'day_of_week', 'trips_count',\n",
    "    'rides_duration_mins', 'total_net_earnings', 'rating'\n",
    "]].copy()\n",
    "\n",
    "# Sort by driver ID and date\n",
    "performance_table = performance_table.sort_values(['earner_id', 'date_formatted'])\n",
    "\n",
    "# Rename columns for better readability\n",
    "performance_table.columns = [\n",
    "    'Driver ID', 'Date', 'Day of Week', 'Daily Trips',\n",
    "    'Total Duration (mins)', 'Total Earnings (â‚¬)', 'Driver Rating'\n",
    "]\n",
    "\n",
    "print(\"Driver Performance Summary - Trips, Duration & Profits per Day\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total Records: {len(performance_table)}\")\n",
    "print(f\"Unique Drivers: {performance_table['Driver ID'].nunique()}\")\n",
    "print(f\"Date Range: {performance_table['Date'].min()} to {performance_table['Date'].max()}\")\n",
    "print(\"\\nFirst 20 records:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Display the table with proper formatting\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "display(performance_table.head(20))"
   ],
   "id": "4dc0db01b864dc10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# Additional Statistics and Insights\n",
    "# ---------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DRIVER PERFORMANCE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Overall statistics\n",
    "print(\"\\nðŸ“Š OVERALL PERFORMANCE METRICS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Average Daily Trips per Driver: {performance_table['Daily Trips'].mean():.2f}\")\n",
    "print(f\"Average Daily Duration per Driver: {performance_table['Total Duration (mins)'].mean():.2f} minutes ({performance_table['Total Duration (mins)'].mean()/60:.1f} hours)\")\n",
    "print(f\"Average Daily Earnings per Driver: â‚¬{performance_table['Total Earnings (â‚¬)'].mean():.2f}\")\n",
    "print(f\"Average Driver Rating: {performance_table['Driver Rating'].mean():.2f}\")\n",
    "\n",
    "# Top performers\n",
    "print(f\"\\nðŸ† TOP PERFORMING DRIVERS (by total earnings):\")\n",
    "print(\"-\" * 40)\n",
    "top_earners = performance_table.groupby('Driver ID').agg({\n",
    "    'Daily Trips': 'sum',\n",
    "    'Total Duration (mins)': 'sum',\n",
    "    'Total Earnings (â‚¬)': 'sum',\n",
    "    'Driver Rating': 'first'\n",
    "}).sort_values('Total Earnings (â‚¬)', ascending=False).head(5)\n",
    "\n",
    "top_earners.columns = ['Total Trips', 'Total Duration (mins)', 'Total Earnings (â‚¬)', 'Rating']\n",
    "display(top_earners)\n",
    "\n",
    "# Efficiency metrics (earnings per trip, earnings per hour)\n",
    "print(f\"\\nðŸ’¡ EFFICIENCY METRICS:\")\n",
    "print(\"-\" * 40)\n",
    "efficiency_table = performance_table.copy()\n",
    "\n",
    "# Calculate efficiency metrics properly (handling zero cases)\n",
    "efficiency_table['Earnings per Trip (â‚¬)'] = efficiency_table.apply(\n",
    "    lambda row: row['Total Earnings (â‚¬)'] / row['Daily Trips'] if row['Daily Trips'] > 0 else 0, axis=1\n",
    ")\n",
    "efficiency_table['Earnings per Hour (â‚¬)'] = efficiency_table.apply(\n",
    "    lambda row: row['Total Earnings (â‚¬)'] / (row['Total Duration (mins)'] / 60) if row['Total Duration (mins)'] > 0 else 0, axis=1\n",
    ")\n",
    "\n",
    "# Calculate averages excluding zeros\n",
    "valid_trips = efficiency_table[efficiency_table['Daily Trips'] > 0]\n",
    "valid_duration = efficiency_table[efficiency_table['Total Duration (mins)'] > 0]\n",
    "\n",
    "print(f\"Average Earnings per Trip: â‚¬{valid_trips['Earnings per Trip (â‚¬)'].mean():.2f}\")\n",
    "print(f\"Average Earnings per Hour: â‚¬{valid_duration['Earnings per Hour (â‚¬)'].mean():.2f}\")\n",
    "\n",
    "# Day of week analysis\n",
    "print(f\"\\nðŸ“… PERFORMANCE BY DAY OF WEEK:\")\n",
    "print(\"-\" * 40)\n",
    "day_performance = performance_table.groupby('Day of Week').agg({\n",
    "    'Daily Trips': 'mean',\n",
    "    'Total Duration (mins)': 'mean',\n",
    "    'Total Earnings (â‚¬)': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "day_performance.columns = ['Avg Daily Trips', 'Avg Duration (mins)', 'Avg Earnings (â‚¬)']\n",
    "display(day_performance)"
   ],
   "id": "cfec5f7964e01361"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# Export Detailed Performance Table\n",
    "# ---------------------------\n",
    "\n",
    "# Create a more detailed table for export/analysis\n",
    "detailed_performance_table = performance_table.copy()\n",
    "\n",
    "# Add efficiency metrics\n",
    "detailed_performance_table['Earnings per Trip (â‚¬)'] = detailed_performance_table.apply(\n",
    "    lambda row: round(row['Total Earnings (â‚¬)'] / row['Daily Trips'], 2) if row['Daily Trips'] > 0 else 0, axis=1\n",
    ")\n",
    "\n",
    "detailed_performance_table['Earnings per Hour (â‚¬)'] = detailed_performance_table.apply(\n",
    "    lambda row: round(row['Total Earnings (â‚¬)'] / (row['Total Duration (mins)'] / 60), 2) if row['Total Duration (mins)'] > 0 else 0, axis=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED DRIVER PERFORMANCE TABLE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total records in table: {len(detailed_performance_table)}\")\n",
    "print(f\"Columns: {list(detailed_performance_table.columns)}\")\n",
    "\n",
    "print(f\"\\nSample of detailed table (first 10 records):\")\n",
    "print(\"-\" * 80)\n",
    "display(detailed_performance_table.head(10))\n",
    "\n",
    "# Optionally save to Excel\n",
    "try:\n",
    "    detailed_performance_table.to_excel('driver_performance_table.xlsx', index=False)\n",
    "    print(f\"\\nâœ… Table exported to 'driver_performance_table.xlsx'\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸ Could not export to Excel: {e}\")\n",
    "\n",
    "# Summary statistics\n",
    "active_drivers = detailed_performance_table[detailed_performance_table['Daily Trips'] > 0]\n",
    "print(f\"\\nðŸ“‹ FINAL SUMMARY:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"â€¢ Total records: {len(detailed_performance_table)}\")\n",
    "print(f\"â€¢ Active driver-days: {len(active_drivers)}\")\n",
    "print(f\"â€¢ Unique drivers: {detailed_performance_table['Driver ID'].nunique()}\")\n",
    "print(f\"â€¢ Date range: {detailed_performance_table['Date'].min()} to {detailed_performance_table['Date'].max()}\")\n",
    "print(f\"â€¢ Total trips across all drivers: {detailed_performance_table['Daily Trips'].sum()}\")\n",
    "print(f\"â€¢ Total earnings across all drivers: â‚¬{detailed_performance_table['Total Earnings (â‚¬)'].sum():.2f}\")\n",
    "print(f\"â€¢ Total working time: {detailed_performance_table['Total Duration (mins)'].sum():.0f} minutes ({detailed_performance_table['Total Duration (mins)'].sum()/60:.1f} hours)\")"
   ],
   "id": "cfd1aeb7c94bc09e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# Load DataFrame from CSV file\n",
    "# ---------------------------\n",
    "\n",
    "# Method 1: Basic CSV loading\n",
    "# Replace 'your_file.csv' with your actual CSV file path\n",
    "csv_file_path = \"data\\data-1759588094558.csv\"\n",
    "\n",
    "try:\n",
    "    # Load CSV into DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    print(f\"Successfully loaded CSV: {csv_file_path}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File '{csv_file_path}' not found. Please check the file path.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV: {e}\")\n",
    "\n"
   ],
   "id": "19f9c20034c300ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.sort_values(['city', 'latitude', 'longitude'], ascending=[False, False, False])\n",
    "df[df['city']==1].describe()\n",
    "df.plot(kind='scatter', x='longitude', y='latitude', alpha=0.5,)\n",
    "# Locationaldf=df.set_index(['city', 'latitude', 'longitude'])[\"predicted_eph\"].to_frame()\n",
    "# Locationaldf.head()"
   ],
   "id": "80dc3445a63a8047"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cityArray= []\n",
    "for i in range(1, 6):\n",
    "    cityArray.append(df[df['city']==i])\n",
    "cityArray[0].describe()\n"
   ],
   "id": "a53ad7383a6cf2a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cityArray[3].plot(kind='scatter', x='longitude', y='latitude', alpha=0.1)\n",
    "rides_trips[rides_trips['city_id']==4].plot(kind='scatter', x='drop_lon', y='drop_lat', alpha=0.1)\n",
    "rides_trips[rides_trips['city_id']==4].plot(kind='scatter', x='pickup_lon', y='pickup_lat', alpha=0.1)\n"
   ],
   "id": "bc27749dd5c5e895"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "i=1\n",
    "latdif = cityArray[i]['latitude'].max() - cityArray[i]['latitude'].min()\n",
    "longdif = cityArray[i]['longitude'].max() - cityArray[i]['longitude'].min()\n",
    "cityArray[i][\"latsector\"] = 0\n",
    "cityArray[i][\"longsector\"] = 0\n",
    "for j in range(1, 101):\n",
    "    lat = cityArray[i].loc[cityArray[i]['latitude'].between(cityArray[i]['latitude'].quantile(0.01*(i-1)), cityArray[i]['latitude'].quantile(0.01*i)), 'latsector'] = j\n",
    "    # lat = cityArray[i]['latitude'].min() + (latdif * j / 100)\n",
    "    if cityArray[i]['latitude'].between(lat - (latdif / 100), lat).any():\n",
    "        cityArray[i].loc[cityArray[i]['latitude'].between(lat - (latdif / 100), lat), 'latsector'] = j\n",
    "    # long = cityArray[i]['longitude'].min() + (longdif * j / 100)\n",
    "    long = cityArray[i].loc[cityArray[i]['longitude'].between(cityArray[i]['longitude'].quantile(0.01*(i-1)), cityArray[i]['longitude'].quantile(0.01*i)), 'longsector'] = j\n",
    "    if cityArray[i]['longitude'].between(long - (longdif / 100), long).any():\n",
    "        cityArray[i].loc[cityArray[i]['longitude'].between(long - (longdif / 100), long), 'longsector'] = j\n",
    "cityArray[i].sort_values(['latsector', 'longsector'], ascending=[True, True], inplace=True)\n",
    "cityArray[i].describe()\n"
   ],
   "id": "b7711afb754cb966"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test = cityArray[i].groupby(['latsector', 'longsector'])['predicted_eph'].mean().unstack()\n",
    "sns.heatmap(test, cmap='YlOrRd', annot=False, cbar_kws={'label': 'Average predicted_eph'})"
   ],
   "id": "7007a60333aa7dc9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
